# llm-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-app-config # referenced in llm-k8-deploy.yaml
data:
  # Environment variables inside containers
  LOG_LEVEL: "INFO"
  N_CTX: "4096"
  N_THREADS: "2"
  # MODEL_FILENAME: "mistral-7b-instruct-v0.1.Q4_K_M.gguf"
  MODEL_PATH: "/src/app/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf"
  N_GPU_LAYERS: "0"
  VERBOSE_LLAMA: "true"

version: '3.8'

services:
  llm_app:
    build:
      context: .  # Directory containing the Dockerfile
      dockerfile: Dockerfile_GPU  # Custom Dockerfile name
    container_name: llm_microservice_app_GPU
    ports:
      - "8000:8000" # Map host port 8000 to container port 8000
    # volumes:
    #   - ./app/models:/models # Mount the local ./models directory to /models in the container
    env_file:
      - .env # Load environment variables from the .env file
    # environment:
    #   # Construct MODEL_PATH using MODEL_FILENAME from .env
    #   MODEL_PATH: /src/app/models/${MODEL_FILENAME}
    # Mount GPU
    deploy:
       resources:
         reservations:
           devices:
             - driver: nvidia
               count: 1 # or 'all'
               capabilities: [gpu]
              #  device_ids: [0]

    restart: unless-stopped
    logging: 
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
